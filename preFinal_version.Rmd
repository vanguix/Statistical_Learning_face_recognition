---
title: "Assignment Statistical Learning"
output: html_notebook
---

# Introduction

The aim of this project is to create a face recognition classifier with two purposes:

-   The first is to be able to predict if an image corresponds to an individual that belongs to a dataset or not.

-   The second is, if the individual belongs to the dataset, to be able to classify the image and determine which category it corresponds to. Being each category a particular individual.

The classifier will be based on the K Nearest Neighbors algorithm, this means it will compute the distances between each picture and select the K closest images, that means the K most similar images. Based on these images and knowing the individuals they correspond to, the category of the new image will be the most common category from these 'closest neighbors'.

Due to the high dimensionality of the images data, it is interesting to consider dimensionality reduction techniques. For this project, Principal Component Analysis and Fisher Discriminant Analysis are considered.

On the one hand, Principal Component Analysis is a technique used for dimensionality reduction and allows to reduce the computation time while aiming to retain the maximum percentage of variance explained.

On the other hand, Fisher Discriminant Analysis aims to introduce a transformation in the data that maximized the inter-class distances while minimizing the intra-class distances. Including Fisher transformation in the data is supposed to improve the performance of the classifier.

# Methodology

This assignment has been structured in two separate parts:

-   The first part uses the PCA and the second one uses the Fisher Discriminant Analysis.

-   For the second part, it was also required to include the PCA to transform the data before using the Fisher Discriminant Analysis. This is due to the large size of the data matrices.

For both cases, the best classifier possible was to be retrieved, for that reason, hyperparameter tuning was required.

For each part, the structure is the same. The required functions have been created, to read the images, to classify, etc. The first step is to load the data and transform each image to the appropriate format.

For hyperparameter tuning it is required to divide the available data into train and test set. This separation has been made taking into account two considerations: for every individual in the training set there are 5 images in the training set and 1 in the test set. Also, two individuals have not been included in the training set and all their images are only in the test set. This procedure aims to develop a classifier that is able to distinguish between people that are in the dataset and people that are not. So the test set is divided into two categories:

-   **test1**: this refers to the images of individuals that belong to the training set.

-   **test2**: this refers to the images of individuals that do not belong to the training set.

Then, the hyperparameters have been optimized, training the classifier in the train set and then computing the performance in the test set. The performance metric that has been used to determine the performance is the *accuracy*. Accuracy is defined as the proportion of accurate predictions the classifier makes.

Finally, with the optimum combination of hyperparameters, the final classifier for each method was created. Additionally, for the case of the PCA, a classifier was implemented using the raw data, this is data with no previous transformation. This was made to analyze the differences when applying PCA.

# Part A

This first part of the assignment, a facial recognizer based on Principal Component Analysis will be implemented. In order to build this classifier, a frontal facial image dataset will be used. This dataset is stored in a folder called 'Training' in the C: disk of the device.

## 1. Definition of the functions

In this first part, the functions that will be used later will be defined and explained. Some functions are required for both the Part A and Part B (read_images, transform_data, split_train_test, our_knn_single) and some others are specific for part A (pca and classifier).

-   **read_images**: this function allows to read the data from every image in a list when the path of each of the files is provided

```{r}
# Include the library OpenImageR that is required to read the images
library(OpenImageR)

read_images <- function(lista_archivos){
  # INPUT
  # file_list - a list with all the paths of the images
  
  # OUTPUT
  # a list with all the data of the images (each item of the list corresponds to one image)
  
  # Create an empty list to store data of the images
  data_images <- list()
  
  i=1
  # Loop to read every image and store its data in the list
  for (archivo in lista_archivos) {
    data_image = readImage(archivo)
    data_images[[i]] <- data_image
    i=i + 1
  }
  print('Images readed.')
  return(data_images)
}
```

-   **transform_data:** it transforms data of every image into a row and adds the results to a matrix, so that the data will be stored in a matrix.

```{r}
transform_data <- function(image_list){
  # INPUT
  # image_list - a list with the data of every image (this was obtained using read_images)
  
  # OUTPUT
  # pic_matrix - a matrix in which every row contains the data of one image
  #              dimensions must be 108000 columns and as many rows as instances

  # Initialize an empty pic_matrix with the right size (right number of columns)
  pic_matrix= matrix(0, nrow = length(image_list), ncol = 108000)
  row_index <- 1

  # Loop to transform the data of every image into a row and adds it to the pic_matrix
  for (i in seq_along(image_list)) {
    pic <- image_list[[i]]
    red <- as.vector(pic[, , 1])
    green <- as.vector(pic[, , 2])
    blue <- as.vector(pic[, , 3])
    flatten_image <- c(red, green, blue)
    pic_matrix[row_index, ] <- flatten_image
    # Verifying that the necessary matrix has the correct dimensions
    #print(dim(pic_matrix))
    row_index <- row_index + 1

  }
  print('Images transformed.')
  return(pic_matrix)
}

```

-   **split_train_test:** performs the separation of the data into sets for training and testing. It returns a dataframe that indicates the label of each image, the path of each image and the set it belongs to (train or test). It also separates between the test1 and test2 sets that have been explained in the methodology.

```{r}

split_train_test <- function(files) {
  # Function to separate between test1, tes2, and train sets
  
  # INPUT
  # files - a list with the paths of the images
  
  # OUTPUT
  # a dataframe with threee columns:
  #      - the path of each image
  #      - the label/identifier of the image
  #      - the set it belongs (it can be: train, test1 or test2)
  
  # Set seed to select people randomly but in the same way in every execution of the code
  set.seed(42)
  
  # Extract label from every image
  images <- c()
  identifiers <- c()
  for (image in files) {
    if (substr(image, nchar(image) - 3 + 1, nchar(image)) == 'jpg') {
      images <- c(images, image)
      label <- gsub(".*?([0-9]+).*", "\\1", image)
      identifiers <- c(identifiers, as.numeric(label)) #there should be 25 ids
    }
  }
  
  # Set up the dataframe with columns file and target
  df <- data.frame(images, as.factor(identifiers))
  names(df) <- c('file', 'target') 
  
  # Randomly select 4 individuals to exclude from training
  set.seed(42)
  excluded_identifiers <- sample(unique(df$target), 4)
  
  # Exclude all the images of the selected individuals from the training set
  df_train_validation <- df[!df$target %in% excluded_identifiers,]
  
  # Randomly select 5 images for training and 1 for testing for each remaining individual
  # Add this images to the dataset 'train' and 'test1'
  df_train_validation <- df_train_validation %>%
    group_by(target) %>%
    mutate(split = sample(c(rep('train', 5), 'test1'), size = n())) %>% #5 IMAGES TO TRAIN, 1 to test
    ungroup()
  
  # Add the excluded identifiers to the 'test2' set
  df_test <- df[df$target %in% excluded_identifiers,]
  df_test$split <- 'test2'
  
  # Combine the datasets
  split_df <- rbind(df_train_validation, df_test)
  print('Train/test splitting completed.')
  return(as.data.frame(split_df))
}


```

-   **pca**: this function applies the PCA to the data it is provided retaining the percentage of variance that is specified. This function returns the mean vector for each column, a vector that contains the percentage of variance retained when adding each principal component, the transformation matrix and the data already transformed with the transformation matrix.

```{r}
pca <- function(data, perc) { 
  # INPUT
  # data - a matrix that contains the data to which we must apply the PCA (a set of observations)
  # perc - a number that determines the percentage of variance that is wanted to be kept, with this parameter it is decided the number of principal componenets that are going to be kept
  
  # OUTPUT
  # result - a list that contains the following elements:
  # mean - a vector that contains the mean of every column (this is useful to center the data) 
  # P - the rotation matrix (this is the matrix we must multiply our data to obtain the data reduced with PCA)
  # D - a vector that contains the variance explained with every new eigenvector that is added
  # reduced_data - the data with dimensionality reduction (that is having applied matrix P)

  cat('PCA calculation begins for perc=', perc, '\n')
  # Calculate the mean of the observations
  mean_vec <- colMeans(data)
  
  # Center the data by subtracting the mean (and we have to decide whether if we scale or not)
  centered_data <- scale(data, center = mean_vec, scale = F)
  
  # Compute the covariance matrix
  cov_matrix <- cov(t(centered_data))
  
  #From now on, we perform everything with the short form of the data matrix (as h<<P).
  # Perform eigenvalue decomposition for the short
  eigen_result <- eigen(cov_matrix) #is the short
  
  # Extract eigenvectors (P) and eigenvalues (e_values)
  e_values <- eigen_result$values #as P will be calculated using the short and the eigenvalues of the long and the short are the same, we direclty calculate them with the short
  P_short <- eigen_result$vectors #this cannot be calculated like this as data is too large (36000*36000) so instead we use the short (n x n) (n - number of instances in the data)
  
  # Percentage of the variance retaining by the PCs
  D<-cumsum(e_values)/sum(e_values) # vector length n

  # Find the index of the first term in the vector D that retains the percentage of variance desired
  index <- sum(D <= perc)+1
  
  # Retain only the elements until that index and rewrite the vector D and the matrix P until that index
  D <- D[1:index] # vector of length m (m<n or m=n)

  P_short <- P_short[,1:index] # matrix dim n * m
  
  #Now we calculate the eigenvectors of the long matrix
  #to do this, we need the eigenvectors of the short and data
  
  #When applying the P eigenvectors 
  P <- t(centered_data)%*%P_short #dim(P) 108000 * m
  reduced_data<-centered_data%*% P # dim(reduced_data) n * m
  
  # Return mean, eigenvectors (matrix P), and variance (matrix D) of the set of observations
  result <- list(mean = mean_vec, P = P, D = D, reduced_data= reduced_data)
  
  cat('PCA calculation finished.\n')
  return(result)
  }

```

-   **our_knn_single**: this function applies the knn classification to the data of an image using the training data stored in 'data'.

```{r}
    our_knn_single = function(data, test, target, friends = 3, threshold = 1400, metric= 'manhattan') {
      # INPUT
      # data - a matrix with the training data (excluding the label)
      # test - a matrix with the test data (the data we want to predict, without the label)
      # target - a vector with the labels for the training data (same number of rows as the data matrix)
      # friends - the number of neighbours to apply the algorithm
      # threshold - the maximum distance for which to consider that the new input belongs to the dataset
      # metric - the method to compute the distance for the classification
      
      # OUTPUT
      # predictions - a list with the predicted classes per each test instance (same number of rows as test matrix)
      
      #cat('KNN begins. Calculation begins for: k= ', friends, ', metric=', metric,  '\n')
      
      # Compute the distances between the test image and the previous data
      aux = rbind(data, test)
      distances = as.matrix(dist(aux),method=metric)
      
      ndata = nrow(data)
      distance = distances[ndata + 1, 1:ndata]
      
      nearest_neighbors <- order(distance)[1:friends]
      neighbor_class <- target[nearest_neighbors]
      tb = table(neighbor_class)

      
      if (min(distance) > threshold) {
        # If the person in the image is not in the training dataset, set to 0
        predicted_class = 0
      } else {
        # If the person in the image is in the training dataset it predicts which is the most similar
        predicted_class = names(tb)[which.max(tb)]
      }
      
      #cat('KNN predictions finished.\n')
      return(predicted_class)
      
    }
```

-   **classifier**: this function classifies the data using the knn and the pca functions.

```{r}
classifier <- function(train_matrix, test_matrix,PCAopt,k,thres,metric='manhattan', perc, target) {
  # INPUT
  # df_train_data - the data (without the label) of the training set (it is a matrix)
  # df_test_data - the data (without the label) of the test set (it is a matrix)
  # PCAopt - binary value 1 if we want to apply PCA, 0 if we do not want to apply PCA
  # k - number of neighbours for the KNN method
  # thres - threshold value to determine whether a new image belongs to the dataset or not
  
  # OUTPUT
  # predictions - a list with the predicted classes per each test instance
  
  #1. Read the files from the dataframe
  #images_train = read_images(df_train_data$file)
  #images_test = read_images(df_test_data$file)
  
  #1. Transform the data
  
  #train_matrix = transform_data(images_train)
  #test_matrix = transform_data(images_test)
  #print('----------------')
  #print(dim(train_matrix))
  #print(dim(test_matrix))
  
  #2. Apply KNN
  
  # Create an empty list to store the predictions
  predictions = list()
  
  if (PCAopt == TRUE) {
    #2.1. Apply the PCA function only to the training
    cat('Option PCA chosen. Calculation begins for: k= ', k, ',Th=', thres, ', metric=', metric, ', perc=', perc,  '\n')
    pca_values = pca(train_matrix, perc)
    
    P= pca_values$P
    means = pca_values$mean
    train_PCA =  pca_values$reduced_data #train data having used PCA to reduce dimensionality
    D = pca_values$D
    
    #2.2. KNN with PCA
    #First, we select the data that will be used for KNN.
    #The training set is already transformed in the previous PCA function.

    
    #The testing set needs to be transformed with the eigenvectors and the mean from
    #the training set after applying PCA.
    centered_data_test <- scale(test_matrix, center = means, scale = F)
    
    
    #When applying the P eigenvectors 
    test_PCA <- centered_data_test %*% P
    
    for (i in 1:nrow(test_PCA)) {
      predicted_class <- our_knn_single(train_PCA, test_PCA[i,], target, friends=k, threshold= thres, metric=metric)
      predictions[i] = predicted_class
    }

  }
  else{
    #2.3. KNN without PCA
    print('Option PCA not chosen.')
    
    for (i in 1:nrow(test_matrix)) {
      predicted_class <- our_knn_single(train_matrix, test_matrix[i,], target, friends=k, threshold= thres, metric=metric)
      predictions[i] = predicted_class
    }
  }
  return(predictions)
}


```

-   **accuracy**: this function computes the accuracies when you specify a prediction and a target.

```{r}
accuracy <- function(prediction, target, test_type){
  # INPUT
  # prediction - a ordered list with the predictions of the model
  # target - a ordered list with the actual labels of the data
  # test_type - a ordered list with the set that every instance belongs to (test1 or test2)
  
  # OUTPUT
  # accuracy - the prediction accuracy of the model

  print('Calculating accuracies')
  corrects=0
  for (i in seq_along(prediction)){
    if(prediction[i]== target[i]){
        corrects= corrects + 1
      }
  }
  accuracy = corrects/length(prediction)
  return(accuracy)
}
```

The accuracy of predicting the target correctly is measured over all possible cases. The reason behind this is that the error is the same when:

-   We predict the target is a concrete person and it is a different one in the dataset

-   We predict the target is a concrete person and the person is not in the dataset

## 2. Hyperparameter tuning

Now that the functions are already created, the parameters must be adjusted to match the problem requirements. The parameters to be adjusted are:

-   the **metric** that is going to be used to compute the distances.

-   the **threshold** distance to determine when the person belongs to the dataset.

-   the **percentage of variance** retained by the PCA.

-   the **number of neighbors** to use with the KNN

But first, we load all the necessary data:

```{r}
library(gridExtra)
library(grid)
library(class)
library(dplyr)

# Specify the directory containing the image files
image_directory <- "C:/Training"

# Obtain the file list with all the files in the folder
files_list <- list.files(path = image_directory, pattern = ".*\\.jpg$", full.names = TRUE)

# Read all the images
images_data = read_images(files_list)

# Transform the data into a matrix that can be used
train_matrix = transform_data(images_data)

print(files_list)
```

### 2.1. Heatmaps

Before starting to tune all the hyperparameters, as a first approach, the heatmaps for different metrics will be plotted. The idea is to look for a metric that helps to distinguish clearly which images correspond to the same person. So, the objective is to look for a metric that maximizes the inter-class distance and minimizes the intra-class distance.

To see visually these distances for different metrics, a heatmap per each different type of metric will be represented. The function **heatmap** previously created will be used. The heatmap will be plotted for both the data without the PCA applied and the data with the PCA applied.

#### 2.1.1. Heatmaps with raw data

```{r}
# Create a list with all the desired methods for distances
metrics = list('euclidean','manhattan','maximum')
for (metric in metrics) {
  # Compute the distances between instances
  distance_matrix= dist(train_matrix, method = metric)
  # Plot a heatmap
  heatmap(as.matrix(distance_matrix),
        main = paste("Heatmap for ", metric, " distance"),
        col= heat.colors(11))

  # Obtain the values of the distances to represent in the legend
  legend("topright", legend = seq(min(distance_matrix), max(distance_matrix), length.out = 11),fill = heat.colors(11), title = "Values", cex = 0.8)
}
```

#### 2.1.2. Heatmaps with PCA

To apply the PCA a percentage of variance retained needs to be specified. As this is just a first approach for the hyperparameter tuning, a value that seems reasonable will be chosen. This value is a 95% of variance explained.

In the following section, the percentage of variance retained along with the other parameters will be tuned.

```{r}
# The percentage of variance retained is specified
var= 0.95

# Apply the PCA to our data
pca_values = pca(train_matrix, var)
train_PCA =  pca_values$reduced_data

# Create a list with all the desired methods for distances
metrics = list('euclidean','manhattan','maximum')

for (metric in metrics) {
  # Compute the distances between instances
  distance_matrix= dist(train_PCA, method = metric)
  
  # Store the distance matrix in the list
  distance_matrices[[metric]] <- distance_matrix
  
  # Plot a heatmap
  heatmap(as.matrix(distance_matrix),
        main = paste("Heatmap for ", metric, " distance"),
        col= heat.colors(11))
  # Obtain the values of the distances to represent in the legend
  legend("topright", legend = seq(min(distance_matrix), max(distance_matrix), length.out = 11),fill = heat.colors(11), title = "Values", cex = 0.8)
}
```

The results in the heatmaps indicate that the Manhattan distance is the one that seems to give better results. The intra-class distances colored in dark red are the lowest and in the heatmap they are easily distinguished. On the other hand, the inter-class distances are higher and are colored in lighter colors.

Another conclusion that can be drawn is that the distance metric that gives the worst results is the 'maximum distance' that does not distinguish well the intra-class and the inter-class, so this will be discarded for the further analysis.

### 2.2. Grid search (for the remaining hyperparameters)

Now this previous analysis has been made, the remaining hyperparameters will be tuned. Still it is not clear if the Manhattan distance or the Euclidean distance will perform better, so both cases will be considered and the one that obtains a better accuracy will be chosen.

First of all, data must be split into train and test sets. The train set will only be used to train the model and the test set to compute the accuracy of the model for each combination of hyperparameters.

```{r}
# Divide the set of images into a test set and train set
all_data = split_train_test(files_list)

# Take the train set and the test set in sepparate dataframes 
df_train_data <- subset(all_data,split == 'train')
df_test_data <- subset(all_data,split != 'train')

# Assign the label '0' to all data in the test2 set, as they don't exist in the train dataset
df_test_data <- df_test_data %>%
  mutate(target = ifelse(split == 'test2', '0', target))


# Read the files from the dataframe
images_train = read_images(df_train_data$file)
images_test = read_images(df_test_data$file)
  
# Transform the data
  
train_matrix = transform_data(images_train)
test_matrix = transform_data(images_test)

```

#### 2.2.1. Grid search for euclidean metric

For the Euclidean metric, a grid search will be performed, iterating over all possible combinations of the remaining hyperparameters (threshold, friends and percentage of variance) and computing the accuracy for each combination.

```{r}
# Initialize a dataframe to store the results
resultados_df_euclidean <- data.frame(metric = character(),
                            threshold = numeric(),
                            percentage_var = numeric(),
                            k_value = numeric(),
                            accuracy = numeric(),
                            stringsAsFactors = FALSE)


results_euclidean = list()
# Compute the distances between instances
distance_matrix_euclidean = distance_matrices[['euclidean']]

thresholds_euclidean = seq(min(distance_matrix_euclidean), max(distance_matrix_euclidean), length.out = 11)

percentage_var= list(0.85,0.90,0.95)

k_values = list(1,3,5) #we choose odd numbers to avoid ties

for (th in thresholds_euclidean) {
  results_euclidean[[as.character(th)]] <- list()
  
  for (var in percentage_var) {
    results_euclidean[[as.character(th)]][[as.character(var)]] <- list()

    for (k_v in k_values) {
      resultado <- classifier(train_matrix, test_matrix, 1, k = k_v, thres = th, metric = 'euclidean', var, df_train_data$target)
      results_euclidean[[as.character(th)]][[as.character(var)]][[as.character(k_v)]] <- resultado

      #a <- sum(as.character(resultado) == as.character(df_test_data$target)) / length(resultado)
      acc <- accuracy(resultado, df_test_data$target, df_test_data$split)

      cat('Accuracy= ', acc, '\n')

      # Almacenar los resultados en el dataframe
      resultados_df_euclidean <- rbind(resultados_df_euclidean, data.frame(metric = "euclidean", threshold = th, percentage_var = var, k_value = k_v, accuracy = acc))
    }
  }
}
```

#### 2.2.2. Grid search for manhattan metric

Now, the same procedure will be repeated with the Manhattan metric:

```{r}
# Initialize a dataframe to store the results
resultados_df_manhattan <- data.frame(metric = character(),
                            threshold = numeric(),
                            percentage_var = numeric(),
                            k_value = numeric(),
                            accuracy = numeric(),
                            stringsAsFactors = FALSE)


results_manhattan = list()
# Compute the distances between instances
distance_matrix_manhattan = distance_matrices[['manhattan']]

thresholds_manhattan = seq(min(distance_matrix_manhattan), max(distance_matrix_manhattan), length.out = 11)

percentage_var= list(0.85,0.90,0.95)

k_values = list(1,3,5) #we choose odd numbers to avoid ties

for (th in thresholds_manhattan) {
  
  for (var in percentage_var) {

    for (k_v in k_values) {
      resultado <- classifier(train_matrix, test_matrix, 1, k = k_v, thres = th, metric = 'manhattan', var, df_train_data$target)
      acc <- accuracy(resultado, df_test_data$target, df_test_data$split)

      cat('Accuracy= ', acc, '\n')

      # Store the results in the dataset
      resultados_df_manhattan <- rbind(resultados_df_manhattan, data.frame(metric = "manhattan", threshold = th, percentage_var = var, k_value = k_v, accuracy = acc))
    }
  }
}

```

Based on the results from the previous executions, the metric that performs the best is the 'euclidean', the threshold that performs the best is around 3954.6 and the number of neighbors seems not to affect the result when it varies between 1, 3 or 5.

#### 2.2.3. Fine tuning grid search

To obtain the best accuracy, now, we are going to define more values for the percentage of variance explained and the threshold around the values that performed better in order to fine-tune these hyperparameters.

```{r}

# Fine tune the threshold and percentage of variance
threshonds_fine = seq(93.48, 4524.22, length.out=11)

percentage_var_fine = seq(0.9,0.99,0.005)

k_v = 3

# Initialize a dataframe to store the results
resultados_df_fine <- data.frame(metric = character(),
                            threshold = numeric(),
                            percentage_var = numeric(),
                            k_value = numeric(),
                            accuracy = numeric(),
                            stringsAsFactors = FALSE)


results_fine = list()

for (th in threshonds_fine) {
  
  for (var in percentage_var_fine) {
   
    resultado <- classifier(train_matrix, test_matrix, 1, k = k_v, thres = th, metric = 'euclidean', var, df_train_data$target)
    acc <- accuracy(resultado, df_test_data$target, df_test_data$split)
    cat('Accuracy= ', acc, '\n')

    # Store the results in the database
    resultados_df_fine <- rbind(resultados_df_fine, data.frame(metric = "euclidean", threshold = th, percentage_var = var, k_value = k_v, accuracy = acc))
  }
}


```

This last stage of fine tuning achieves accuracies of 1.00, which is the best possible value to achieve.

### 2.3. Hyperparameter decision

Once these studies have been performed, it has been verified that the metric of the distance that classifies better is the 'euclidean' distance.

For the number of neighbors, it has been proved that 1, 3 and 5 neighbors obtain the same results. Based on this, the chosen value for k is 3 because between 1,3 and 5 it is going to be more robust than choosing k = 1. Also, fine tuning lets us know that the optimum accuracy is reached when the threshold oscillates between 1865.776 and 2751.924 independently of the percentage of variance explained. So an average value between these two has been chosen: 2308.85

The percentage of variance explained does not change from 0.9 to 0.99, so the value chosen is 0.9, because it is the one that retains less components and so, computationaly more efficient.

| **metric** | **threshold** | **perc_var** | **k_value** | **accuracy** |
|:-----------|:--------------|:-------------|:------------|:-------------|
| euclidean  | 2308.85       | 0.9          | 3           | 1.00         |

## 3. Classifying without dimensionality reduction

Now, classifying without using the PCA, to compare the results from PCA and without PCA. Again some hyperparameter tuning is required to optimize the performance of the classifier.

### 3.1. Choosing the threshold for raw data

According to previous results and to the heatmaps shown in section 2.1.1., the metric that performs better is the euclidean.

The number of neighbors that performs best is 3 as it is explained before.

The threshold must be tuned again, because the values for threshold change when applying PCA, so this hyperparameter will be tuned in an iterative way.

The percentage of variance explained does not apply, as the PCA is not implemented in this section.

```{r}
# Tuning the threshold

# Initialize a dataframe to store the results
resultados_df_raw <- data.frame(
  threshold = numeric(),
  accuracy = numeric(),
  stringsAsFactors = FALSE)

results_raw = list()
# Compute the distances between instances
distance_matrix_raw= dist(train_matrix, method = 'euclidean')

# Stablish the values of the hyperparameters 
k_v = 3
var = 0.9 # as the function is defined it is required to specify the percentage of variance explained but it is not used as PCA is not applied
# From the results of the heatmaps, the best threshold seems to be between those values
thresholds_raw = seq(min(distance_matrix_raw), max(distance_matrix_raw), length.out = 11)

for (th in thresholds_raw) {
  resultado <- classifier(train_matrix, test_matrix, 0, k = k_v, thres = th, metric = 'euclidean', var, df_train_data$target)
  acc <- accuracy(resultado, df_test_data$target, df_test_data$split)
  cat('Accuracy= ', acc, '\n')

  # Store the results in the dataframe
  resultados_df_raw <- rbind(resultados_df_raw, data.frame(threshold = th, accuracy = acc))

}
```

### 3.2. Model with raw data

With these results, the optimum hyperparameters for the raw data model are the following:

| **metric** | **threshold** | **perc_var** | **k_value** | **accuracy** |
|:-----------|:--------------|:-------------|:------------|:-------------|
| euclidean  | maría         | 0.9          | 3           | 1.00         |

## 4. Training of the final PCA model

The final model will use the PCA dimensionality reduction because it obtains an accuracy of 1.00 and is also faster. Also, it will use the optimum hyperparameters that have been already calculated in the previous sections. The classifier that uses PCA will be defined here but also in another R script.

For the final model, the complete training set will be used, not leaving for testing, in order to get the best possible performance of the final model.

The transformation matrix P, the transformed train data, the means of the columns, the percentage of variance explained D, and the target of the training data will be stored in a Rdata file. This saves time from reading and transforming the training data each time.

```{r}
# Specify the directory containing the image files
image_directory <- "C:/Training"

# Obtain the file list with all the files in the folder
files_list <- list.files(path = image_directory, pattern = ".*\\.jpg$", full.names = TRUE)

# Read all the images
images_data = read_images(all_data$file)

# Transform the data into a matrix that can be used
matrix_data = transform_data(images_data)

# Save the required matrices and vectors in a Rdata file
pca_values = pca(matrix_data, 0.95)
P_pca= pca_values$P
means_pca = pca_values$mean
train_pca =  pca_values$reduced_data 
D_pca= pca_values$D
target = all_data$target
save(file='PCA_data.Rdata', P_pca,means_pca,train_pca,D_pca,target, our_knn_single)

```

```{r}
PCA_Classifier <- function(name){
  # INPUT
  # name - name of the image that is going to be tested, example 'anonym1.jpg'
  # NOTE: the image must be in the same path as the R file
  
  # OUTPUT
  # predicted_class - classification of the image (number ID)
  
  # Here, the optimum hyperparameters are used
  threshold = 2800
  metric = 'euclidean'
  friends = 3
  
  # Include required libraries and Rdata files
  library(OpenImageR)
  load("PCA_data.Rdata")
  # NOTE: PCA_data.Rdata must be in the same folder
  # This will load:
  #    P_pca - the transformation matrix
  #    train_pca - the matrix of the training data once applied PCA
  #    D_pca - the vector that specifies which percentage of variance is retained per each PC
  #    means_pca - the vector of the means
  
  # Read and transform the test image
  image_directory <- name
  data_image = readImage(image_directory)
  
  red <- as.vector(data_image[, , 1])
  green <- as.vector(data_image[, , 2])
  blue <- as.vector(data_image[, , 3])
  test_image <- c(red, green, blue)
  
  print(length(test_image))
  print(length(means_pca))
  
  #Centering the data
  #centered_test <- scale(test_image, center = means_pca, scale = F)
  centered_test <- test_image - means_pca
  
  # Apply the transformation to the test data
  test_PCA = centered_test %*% P_pca
  
  predicted_class <- our_knn_single(train_pca, test_PCA, target, friends=3, threshold= 2800, metric='euclidean')
  
  return(predicted_class)
}
```

Now, we can try the model with the validation images that have been provided:

```{r}
PCA_Classifier("anonym1.4.jpg") #out of the dataset -> should be 0
PCA_Classifier("9332898.15.jpg") #in the dataset -> should be 2
PCA_Classifier("pspliu.1.jpg") #out of the dataset -> should be 0

```

# Part B

## 1. Definition of the functions

For the part B, most functions from the part A will be used. But additionally, it is required to create some new functions to perform the Fisher Discriminant Analysis and to classify the data using this analysis:

-   **fisher_lda**: this function performs the Fisher Discriminant Analysis and returns the transformed data, the transformation matrix, the percentage of variance explained by each component and the mean per columns.

```{r}
fisher_lda <- function(data, labels, perc_fish, perc_pca=0.9) {
  # INPUT
  # data -> data matrix (each row is a sample, each column is a feature)
  # labels -> vector (each element is the label of each sample)
  # perc -> percentage of variance eplained wanted to retain
  
  # OUTPUT
  # The function returns a list with the following elements:
  # mean - a vector that contains the mean of every column (this is useful to center the data) 
  # W - the transformation matrix (this is the matrix we must multiply our data to obtain the data tranformed with Fisher)
  # projected_data - the data with dimensionality reduction (that is having multiplied our original data by matrix W)
  # D - a vector that contains the variance explained with every new eigenvector that is added
  
  # Number of classes to dimension all the matrices and vectors
  num_classes <- length(unique(labels))
  
  # Initialize empty Scatter Matrices with appropriate dimensions
  pca_result = pca(data,perc_pca)
  data_pca = pca_result$reduced_data
  
  # Compute Overall Mean per columns
  overall_mean <- colMeans(data_pca)
  
  # Initialize the covariance within and covariance between matrices
  Sw <- matrix(0, ncol = ncol(data_pca), nrow = ncol(data_pca))
  Sb <- matrix(0, ncol = ncol(data_pca), nrow = ncol(data_pca))

  # Loop over classes to compute the Sb_class, Sw_class and update the Sw and Sb
  for (class_label in unique(labels)) {
    
    cat('Iteration for label: ',class_label, '\n')
    
    # Select the data for the current class
    X_class <- data_pca[labels == class_label, ]
    
    # Compute class mean
    mean_class <- colMeans(X_class)
    
    # Within-Class Scatter Matrix (Sw)
    Sw_class <- cov(X_class) * (nrow(X_class) - 1)  # Covariance matrix multiplied by (n-1)
    Sw <- Sw + Sw_class
                    
    # Between-Class Scatter Matrix (Sb)
    Sb_class <- nrow(X_class) * (mean_class - overall_mean) %*% (t(mean_class - overall_mean))
    Sb <- Sb + Sb_class
  }
  
  # Solve the generalized eigenvalue problem
  eig_result <- eigen(solve(Sw) %*% Sb)
 
  # Order the eigen
  sorted_indices <- order(eig_result$values, decreasing = TRUE)
  eig_result$values <- eig_result$values[sorted_indices]
  eig_result$vectors <- eig_result$vectors[, sorted_indices]

  # Get the eigenvectors corresponding to the largest eigenvalues
  num_eigenvectors <- min(num_classes - 1, ncol(data) - 1)  # Maximum number of non-zero eigenvalues
  W <- eig_result$vectors[, 1:num_eigenvectors]
  print(dim(W))
  # Get the vector D that contains the percentage of variance explained per component
  eigen_values = eig_result$values[1:num_eigenvectors]
  D = cumsum(eigen_values)/sum(eigen_values)
  
  # Find the index of the first term in the vector D that retains the percentage of variance desired
  index <- which(D >= perc_fish)[1]
  
  # Retain only the elements until that index and rewrite the vector D and the matrix W until that index
  D <- D[1:index] # vector of length m (m<n or m=n)
  W <- W[,1:index]
  
  # Project the data
  projected_data <- data_pca %*% W
  
  # Return the projection matrix, the projected data and the vector with percentage of variance explained
  return(list(mean = overall_mean, W = W, projected_data = projected_data, D=D))
}

```

-   **classifier_fisher**: this function performs the classification but in this case it performs the Fisher Discriminant Analysis.

```{r}
classifier_fisher <- function(train_matrix, test_matrix,k,thres,metric='manhattan', perc, target) {
  # INPUT
  # df_train_data - the data (without the label) of the training set (it is a matrix)
  # df_test_data - the data (without the label) of the test set (it is a matrix)
  # k - number of neighbours for the KNN method
  # thres - threshold value to determine whether a new image belongs to the dataset or not
  
  # OUTPUT
  # it returns the output of the knn applied
  
  #1. Read the files from the dataframe
  #images_train = read_images(df_train_data$file)
  #images_test = read_images(df_test_data$file)
  
  #1. Transform the data
  
  #train_matrix = transform_data(images_train)
  #test_matrix = transform_data(images_test)
  #print('----------------')
  #print(dim(train_matrix))
  #print(dim(test_matrix))
  
  #2. Apply KNN
  
  # Create an empty list to store the predictions
  predictions = list()
  

  #2.1. Apply the Fisher Discriminant Analysis
  fisher_values = fisher_lda(train_matrix, target, perc_fish = perc)
  
  W = fisher_values$W
  means_fisher = fisher_values$mean
  train_fisher =  fisher_values$projected_data #train data having used PCA to reduce dimensionality
  D = fisher_values$D
  
  #2.2. KNN with PCA
  #First, we select the data that will be used for KNN.
  #The training set is already transformed in the previous PCA function.

  
  #The testing set needs to be transformed with the eigenvectors and the mean from
  #the training set after applying PCA.
  
  pca_values = pca(train_matrix, 0.9)
  P= pca_values$P
  means_pca = pca_values$mean
  train_PCA =  pca_values$reduced_data #train data having used PCA to reduce dimensionality
  D = pca_values$D
  centered_data_test <- scale(test_matrix, center = means_pca, scale = F)
  
  print(dim(centered_data_test)) #matrix
  print(dim(P)) #matrix
  
  #When applying the P eigenvectors 
  test_PCA <- centered_data_test %*% P
  
  print(dim(test_PCA)) #matrix
  print(dim(W)) #matrix
  
  #When applying the P eigenvectors 
  test_fisher <- test_PCA %*% W
  
  for (i in 1:nrow(test_fisher)) {
    predicted_class <- our_knn_single(train_fisher, test_fisher[i,], target, friends=k, threshold= thres, metric=metric)
    predictions[i] = predicted_class
  }

  
  return(predictions)
}


```

## 2. Hyperparameter tuning

### 2.1. Heatmaps with Fisher

```{r}
# We define the percentage of variance for the fisher
var= 0.95
# Apply fisher
fisher_values = fisher_lda(train_matrix,df_train_data$target,var)
train_fisher =  fisher_values$projected_data
metrics = list('euclidean','manhattan','maximum')

distance_matrices <- list()

for (metric in metrics) {
  # Compute the distances between instances
  distance_matrix= dist(train_fisher, method = metric)
  
  # Store the distance matrix in the list
  distance_matrices[[metric]] <- distance_matrix
  
  # Plot a heatmap
  heatmap(as.matrix(distance_matrix),
        main = paste("Heatmap for ", metric, " distance"),
        col= heat.colors(11))

  # Obtener los valores únicos en la matriz
  legend("topright", legend = seq(min(distance_matrix), max(distance_matrix), length.out = 11),fill = heat.colors(11), title = "Values", cex = 0.8)
}
```

### 2.2. Grid search for hyperparameter tuning

```{r}
# Initialize a dataframe and a list to store the results
resultados_df_euclidean <- data.frame(metric = character(),
                            threshold = numeric(),
                            percentage_var = numeric(),
                            k_value = numeric(),
                            accuracy = numeric(),
                            stringsAsFactors = FALSE)
results_euclidean = list()

# Compute the distances between instances
distance_matrix_euclidean = distance_matrices[['euclidean']]

# Define the hyperparameter values we want to try
thresholds_euclidean = seq(min(distance_matrix_euclidean), max(distance_matrix_euclidean), length.out = 11)
percentage_var= list(0.85,0.90,0.95)
k_values = list(1,3,5) #we choose odd numbers to avoid ties

# Iterate over the different hyperparameter combinations to find accuracies
for (th in thresholds_euclidean) {

  for (var in percentage_var) {

    for (k_v in k_values) {
      resultado <- classifier_fisher(train_matrix, test_matrix, k_v, th, metric = 'euclidean', var, df_train_data$target)
      
      #a <- sum(as.character(resultado) == as.character(df_test_data$target)) / length(resultado)
      acc <- accuracy(resultado, df_test_data$target, df_test_data$split)

      cat('Accuracy= ', acc, '\n')

      # Almacenar los resultados en el dataframe
      resultados_df_euclidean <- rbind(resultados_df_euclidean, data.frame(metric = "euclidean", threshold = th, percentage_var = var, k_value = k_v, accuracy = acc ))
    }
  }
}
```

### 2.3. Hyperparameter decision

The grid search made before, obtains the best result for the following hyperparameters:

| **metric** | **threshold** | **perc_var** | **k_value** | **accuracy** |
|:-----------|:--------------|:-------------|:------------|:-------------|
| euclidean  | 980.6         | 0.95         | 3           | 1            |

## 3. Training of the final Fisher model

```{r}
# Specify the directory containing the image files
image_directory <- "C:/Training"

# Obtain the file list with all the files in the folder
files_list <- list.files(path = image_directory, pattern = ".*\\.jpg$", full.names = TRUE)

# Read all the images
images_data = read_images(all_data$file)

# Transform the data into a matrix that can be used
matrix_data = transform_data(images_data)

# Save the required matrices and vectors in a Rdata file
pca_values = pca(matrix_data, 0.9)
P_pca= pca_values$P
means_pca = pca_values$mean
train_pca =  pca_values$reduced_data 
D_pca= pca_values$D
target = all_data$target

fisher_values = fisher_lda(matrix_data, target, perc_fish = 0.95)
W = fisher_values$W
means_fisher = fisher_values$mean
train_fisher =  fisher_values$projected_data #train data having used PCA to reduce dimensionality
D_fisher = fisher_values$D
  
save(file='Fisher_data.Rdata', P_pca,means_pca,train_pca,D_pca,target,W, means_fisher, train_fisher, D_fisher, our_knn_single)


```

```{r}
Fisher_Classifier <- function(name){
  # INPUT
  # name - name of the image that is going to be tested, example 'anonym1.jpg'
  # NOTE: the image must be in the same path as the R file
  
  # OUTPUT
  # predicted_class - classification of the image (number ID)
  
  # Use the optimum hyperparameters
  metric = 'euclidean'
  threshold = 980.6
  friends = 3 
  
  # Include required libraries and Rdata files
  library(OpenImageR)
  load("Fisher_data.Rdata")
  # NOTE: Fisher_data.Rdata must be in the same folder
  # This will load:
  #    P_pca - the transformation matrix
  #    train_pca - the matrix of the training data once applied PCA
  #    D_pca - the vector that specifies which percentage of variance is retained per each PC
  #    means_pca - the vector of the means
  #    target -
  #     W -
  #means -
  #     train_
  #     D_Fisher
  
  # Read and transform the test image
  image_directory <- name
  data_image = readImage(image_directory)
  
  red <- as.vector(data_image[, , 1])
  green <- as.vector(data_image[, , 2])
  blue <- as.vector(data_image[, , 3])
  test_image <- c(red, green, blue)
  
  centered_test <- test_image - means_pca

  # Apply the transformation to the test data
  test_PCA <- centered_test %*% P_pca
  
  test_Fisher <- test_PCA %*% W
  
  predicted_class <- our_knn_single(train_fisher, test_Fisher, target, friends=3, threshold= 980.6, metric='euclidean')
  
  return(cat("The predicted class is: ", predicted_class))
}
```

```{r}
Fisher_Classifier("anonym1.4.jpg")
Fisher_Classifier("9332898.15.jpg")
Fisher_Classifier("pspliu.1.jpg")
```

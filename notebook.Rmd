---
title: "Assignment Statistical Learning"
output: html_notebook
---

# PART A

This first part of the assignment, a facial recognizer based on principal component analysis will be implemented. In order to build this classifier, a frontal facial image dataset will be used. This dataset is stored in a folder called 'Training' in the C: disk of the device.

## DEFINITION OF THE FUNCTIONS

In this first part, the functions that will be used later will be defined and explained.

-   **read_images**: this function allows to read the data from every image in a list when the path of each of the files is provided

```{r}
# Include the library OpenImageR that is required to read the images
library(OpenImageR)

read_images <- function(lista_archivos){
  # INPUT
  # file_list - a list with all the paths of the images
  
  # OUTPUT
  # a list with all the data of the images (each item of the list corresponds to one image)
  
  # Create an empty list to store data of the images
  data_images <- list()
  
  i=1
  # Loop to read every image and store its data in the list
  for (archivo in lista_archivos) {
    data_image = readImage(archivo)
    data_images[[i]] <- data_image
    i=i + 1
  }
  print('Images readed.')
  return(data_images)
}
```

-   **transform_data:** it transforms data of every image into a row and adds the results to a matrix, so that the data will be stored in a matrix.

```{r}
transform_data <- function(image_list){
  # INPUT
  # image_list - a list with the data of every image (this was obtained using read_images)
  
  # OUTPUT
  # pic_matrix - a matrix in which every row contains the data of one image
  #              dimensions must be 108000 columns and as many rows as instances

  # Initialize an empty pic_matrix with the right size (right number of columns)
  #pic_matrix <- matrix(nrow = 0, ncol = 108000)  # Must have 108000 columns
  
  #esto es de pepe
  pic_matrix= matrix(0, nrow = length(image_list), ncol = 108000)
  row_index <- 1

  # Loop to transform the data of every image into a row and adds it to the pic_matrix
  for (i in seq_along(image_list)) {
    pic <- image_list[[i]]
    
    red <- as.vector(pic[, , 1])
    green <- as.vector(pic[, , 2])
    blue <- as.vector(pic[, , 3])
    
    #new_row <- t(as.vector(pic))
    #pic_matrix <- rbind(pic_matrix, new_row)
    flatten_image <- c(red, green, blue)
    pic_matrix[row_index, ] <- flatten_image
    # Verifying that the necessary matrix has the correct dimensions
    #print(dim(pic_matrix))
    row_index <- row_index + 1

  }
  print('Images transformed.')
  return(pic_matrix)
}

```

-   **split_train_test:** performs the separation of the data into sets for training and testing. It returns a dataframe that indicates the label of each image, the path of each image and the set it belongs to (train or test).

EXPLAIN WHAT IS TEST1 AND TEST2!!!!!!!!!!!!!!!!!!!!

```{r}

split_train_test <- function(files) {
  # Function to separate between test1, tes2, and train sets
  # INPUT
  # files - a list with the paths of the images
  
  # OUTPUT
  # a dataframe with threee columns:
  #      - the path of each image
  #      - the label/identifier of the image
  #      - the set it belongs (it can be: train, test1 or test2)
  
  #To select people randomly but in the same way in every execution of the code
  set.seed(42)
  
  # Extract label from every image
  images <- c()
  identifiers <- c()
  for (image in files) {
    if (substr(image, nchar(image) - 3 + 1, nchar(image)) == 'jpg') {
      images <- c(images, image)
      label <- gsub(".*?([0-9]+).*", "\\1", image) #1 refers to first
      identifiers <- c(identifiers, as.numeric(label)) #there should be 25 ids
    }
  }
  
  # Set up the dataframe with columns file and target
  df <- data.frame(images, as.factor(identifiers))
  names(df) <- c('file', 'target') 
  
  # Randomly select 4 identifiers to exclude from training
  set.seed(42)
  excluded_identifiers <- sample(unique(df$target), 4)
  
  # Exclude the selected identifiers from the training set
  df_train_validation <- df[!df$target %in% excluded_identifiers,]
  
  # Randomly select 5 images for training and 1 for testing for each remaining identifier
  # Add this images to the dataset 'train' and 'test1'
  df_train_validation <- df_train_validation %>%
    group_by(target) %>%
    mutate(split = sample(c(rep('train', 5), 'test1'), size = n())) %>% #5 IMAGES TO TRAIN, 1 to test
    ungroup()
  
  # Add the excluded identifiers to the 'test2' set
  df_test <- df[df$target %in% excluded_identifiers,]
  df_test$split <- 'test2'
  
  # Combine the datasets
  split_df <- rbind(df_train_validation, df_test)
  print('Train/test splitting completed.')
  return(as.data.frame(split_df))
}


```

-   **pca**: this function applies the PCA to the data it is provided.

```{r}
pca <- function(data, perc) { 
  # INPUT
  # data - a matrix that contains the data to which we must apply the PCA (a set of observations)
  # perc - a number that determines the percentage of variance that is wanted to be kept, with this parameter it is decided the number of principal componenets that are going to be kept
  
  # OUTPUT
  # result - a list that contains the following elements:
  # mean - a vector that contains the mean of every column (this is useful to center the data) 
  # P - the rotation matrix (this is the matrix we must multiply our data to obtain the data reduced with PCA)
  # D - a vector that contains the variance explained with every new eigenvector that is added
  # reduced_data - the data with dimensionality reduction (that is having applied matrix P)

  cat('PCA calculation begins for perc=', perc, '\n')
  # Calculate the mean of the observations
  mean_vec <- colMeans(data)
  
  # Center the data by subtracting the mean (and we have to decide whether if we scale or not)
  centered_data <- scale(data, center = mean_vec, scale = F) #cambiar centrer = T y ver si sale igual
  
  # Compute the covariance matrix
  cov_matrix <- cov(t(centered_data))
  
  #From now on, we perform everything with the short form of the data matrix (as h<<P).
  # Perform eigenvalue decomposition for the short
  
  eigen_result <- eigen(cov_matrix) #is the short
  
  # Extract eigenvectors (P) and eigenvalues (e_values)
  e_values <- eigen_result$values #as P will be calculated using the shot and the eigenvalues of the long and the short are the same, we direclty calculate them with the short
  P_short <- eigen_result$vectors #this cannot be calculated like this as data is too large (36000*36000) so instead we use the short (n x n) (n - number of instances in the data)
  
  # Percentage of the variance retaining by the PCs
  D<-cumsum(e_values)/sum(e_values) # vector length n

  # Find the index of the first term in the vector D that retains the percentage of variance desired
  #index <- which(D >= perc)[1]
  index <- sum(D <= perc)+1
  
  # Retain only the elements until that index and rewrite the vector D and the matrix P until that index
  D <- D[1:index] # vector of length m (m<n or m=n)

  P_short <- P_short[,1:index] # matrix dim n * m
  
  #Now we calculate the eigenvectors of the long matrix
  #to do this, we need the eigenvectors of the short and data
  
  #When applying the P eigenvectors 
  P <- t(centered_data)%*%P_short #dim(P) 108000 * m
  reduced_data<-centered_data%*% P # dim(reduced_data) n * m
  
  # Return mean, eigenvectors (matrix P), and variance (matrix D) of the set of observations
  result <- list(mean = mean_vec, P = P, D = D, reduced_data= reduced_data)
  
  cat('PCA calculation finished.\n')
  return(result)
  }

```

-   **our_knn_multiple**: this function applies the knn classification to 'tests' using the training data stored in 'data'.

```{r}
our_knn_multiple = function(data, tests, target, friends = 3, threshold=40, metric= 'manhattan') {
  # INPUT
  # data - a matrix with the training data (excluding the label)
  # test - a matrix with the test data (the data we want to predict, without the label)
  # target - a vector with the labels for the training data (same number of rows as the data matrix)
  # friends - the number of kneighbours to apply the algorithm
  # threshold - the maximum distance for which to consider that the new input belongs to the dataset
  # metric - the method to compute the distance for the classification
  
  # OUTPUT
  # predictions - a list with the predicted classes per each test instance (same number of rows as test matrix)
  cat('KNN begins. Calculation begins for: k= ', friends, ',Th=', threshold, ', metric=', metric,  '\n')
  predictions = list()
  
  for (i in 1:nrow(tests)) {
    test = tests[i, , drop = FALSE]
    aux = rbind(data, test)
    distances = as.matrix(dist(aux),method=metric)
    ndata = nrow(data)
    distances = distances[ndata + 1, 1:ndata]
    
    if (min(distances)>threshold) {
      # if the person in the image is not in the training dataset, 0
      predicted_class= '0'
      }
    else{
      ind = sort(distances, index.return = TRUE)
      idx = ind$ix[1:friends]
      neighbors = data[idx,]
      neighbors_class = target[idx]
      tb = table(neighbors_class)
      predicted_class = names(tb)[which.max(tb)]
    }
  
    predictions[[i]] = predicted_class
  }
  cat('KNN predictions finished.\n')
  return(predictions)
}
```


```{r}
our_knn_multiple = function(data, test_matrix, target, friends = 3, threshold = 40, metric = 'manhattan') {
  # INPUT
  # data - a matrix with the training data (excluding the label)
  # test_matrix - a matrix with the test data (the data we want to predict, without the label)
  # target - a vector with the labels for the training data (same number of rows as the data matrix)
  # friends - the number of kneighbours to apply the algorithm
  # threshold - the maximum distance for which to consider that the new input belongs to the dataset
  # metric - the method to compute the distance for classification
  
  # OUTPUT
  # predictions - a vector with the predicted classes for each test instance (same number of rows as test_matrix)
  cat('KNN begins. Calculation begins for: k=', friends, ', Th=', threshold, ', metric=', metric,  '\n')
  predictions = list()
  
  for (i in 1:nrow(test_matrix)) {
    test = test_matrix[i, , drop = FALSE]
    distances <- as.matrix(dist(rbind(data, test), method = metric))
    distance = distances[nrow(distances), 1:ncol(distances) - 1]
  
    if (min(distance) > threshold) {
      # If the person in the image is not in the training dataset, set to 0
      predicted_class = 0
    } else {
      ind = sort(distance, index.return = TRUE, decreasing = FALSE)
      neighbors = target[ind$ix[1:friends]]
      tb = table(neighbors)
      predicted_class = names(tb)[which.max(tb)]
    }
    
    predictions[[i]] = predicted_class
  }
  
  cat('KNN predictions finished.\n')
  return(predictions)
}

```


-   **classifier**: this function classifies the data using the knn and the pca functions.

```{r}
classifier <- function(train_matrix, test_matrix,PCAopt,k,thres,metric='manhattan', perc, target) {
  # INPUT
  # df_train_data - the data (without the label) of the training set (it is a matrix)
  # df_test_data - the data (without the label) of the test set (it is a matrix)
  # PCAopt - binary value 1 if we want to apply PCA, 0 if we do not want to apply PCA
  # k - number of neighbours for the KNN method
  # thres - threshold value to determine whether a new image belongs to the dataset or not
  
  # OUTPUT
  # it returns the output of the knn applied
  
  #1. Read the files from the dataframe
  #images_train = read_images(df_train_data$file)
  #images_test = read_images(df_test_data$file)
  
  #1. Transform the data
  
  #train_matrix = transform_data(images_train)
  #test_matrix = transform_data(images_test)
  #print('----------------')
  #print(dim(train_matrix))
  #print(dim(test_matrix))
  
  #2. Apply KNN
  if (PCAopt == TRUE) {
    #2.1. Apply the PCA function only to the training
    cat('Option PCA chosen. Calculation begins for: k= ', k, ',Th=', thres, ', metric=', metric, ', perc=', perc,  '\n')
    pca_values = pca(train_matrix, perc)
    
    P= pca_values$P
    means = pca_values$mean
    train_PCA =  pca_values$reduced_data #train data having used PCA to reduce dimensionality
    D = pca_values$D
    
    #2.2. KNN with PCA
    #First, we select the data that will be used for KNN.
    #The training set is already transformed in the previous PCA function.
    datos_train = data.frame(train_PCA)
    
    #The testing set needs to be transformed with the eigenvectors and the mean from
    #the training set after applying PCA.
    centered_data_test <- scale(test_matrix, center = means, scale = F)
    
    
    #When applying the P eigenvectors 
    test_PCA <- centered_data_test %*% P
    
    datos_test = data.frame(test_PCA)
    
    knn_applied <- our_knn_multiple(train_PCA, test_PCA, target, friends=k, threshold= thres, metric=metric)
  }
  else{
    #2.3. KNN without PCA
    print('Option PCA not chosen.')
    knn_applied <- our_knn_multiple(train_matrix, test_matrix, target, friends=k, threshold= thres, metric=metric)
  }
  return(knn_applied)
}


```

-   **accuracy**: this function compute the accuracies when you specify a prediction and a target.

```{r}

accuracy <- function(prediction, target, test_type ){
  # INPUT
  # prediction - a ordered list with the predictions of the model
  # target - a ordered list with the actual labels of the data
  # test_type - a ordered list with the set that every instance belongs to (test1 or test2)
  
  # OUTPUT
  # it returns a list with two accuracies:
  # accuracy_belong: it is the accuracy of the model to predict whether an instance belongs or not to the dataset
  # accuracy_target: it is the accuracy of the model to predict the correct category of the instance
  print('Calculating accuracies')
  corrects_belong= 0
  corrects_target=0
  for (i in seq_along(prediction)){
    if ((prediction[i] == '0' & test_type[i]=='test2') | (prediction[i] != '0' & test_type[i]=='test1')){
      corrects_belong = corrects_belong + 1 
      
      if(prediction[i]== target[i]){
        corrects_target= corrects_target + 1
      }
      }
  }
  
  accuracy_belong= corrects_belong/ length(prediction)
  accuracy_target = corrects_target/ length(prediction)
  return((list(accuracy_belong = accuracy_belong, accuracy_target = accuracy_target)))
}
```

The accuracy of predicting the target correctly is measured over all possible cases. The reason behind this is that the error is the same when:

-   We predict the target is a concrete person and it is a different one in the dataset

-   We predict the target is a concrete person and the person is not in the dataset

## DETERMINATION OF THE PARAMETERS

Now that the functions are already created, the parameters must be adjusted to match the problem requirements. The parameters to be adjusted are:

-   the **metric** that is going to be used to compute the distances.

-   the **threshold** distance to determine when the person belongs to the dataset.

-   the **percentage of variance** retained by the PCA.

-   the **number of neighbors** to use with the KNN


But first, we load all the necessary data:
```{r}
library(gridExtra)
library(grid)
library(class)
library(dplyr)

# Specify the directory containing the image files
image_directory <- "C:/Training"

# Obtain the file list with all the files in the folder
files_list <- list.files(path = image_directory, pattern = ".*\\.jpg$", full.names = TRUE)

# Read all the images
images_data = read_images(files_list)

# Transform the data into a matrix that can be used
train_matrix = transform_data(images_data)
```


### SIMILARITY METRIC???

The first hyperparameter that is going to be adjusted is the metric of the distances. The idea is to look for a metric that helps to distinguish clearly which images correspond to the same person. So, the objective is to look for an image that maximizes the inter-class distance and minimizes the intra-class distance.

To see visually these distances for different metrics, a heatmap per each different type of metric will be represented. A function has been created to plot the heatmap with the desired specifications for every metric.

##### heatmaps with raw data 

```{r}
# Create a list with all the desired methods for distances
metrics = list('euclidean','manhattan','maximum')
for (metric in metrics) {
  # Compute the distances between instances
  distance_matrix= dist(train_matrix, method = metric)
  # Plot a heatmap
  heatmap(as.matrix(distance_matrix),
        main = paste("Heatmap for ", metric, " distance"),
        col= heat.colors(11))

  # Obtener los valores únicos en la matriz
  legend("topright", legend = seq(min(distance_matrix), max(distance_matrix), length.out = 11),fill = heat.colors(11), title = "Values", cex = 0.8)
}
```


##### heatmaps with PCA

hay que poner una varianza pero yo elegiría la máxima (tipo 0.9 o 0.95) porque es solo por hacer dibujitos, luego en verdad vamos a testear todo con accuracies

```{r}
var= 0.95
pca_values = pca(train_matrix, var)
train_PCA =  pca_values$reduced_data
metrics = list('euclidean','manhattan','maximum')

distance_matrices <- list()

for (metric in metrics) {
  # Compute the distances between instances
  distance_matrix= dist(train_PCA, method = metric)
  
  # Store the distance matrix in the list
  distance_matrices[[metric]] <- distance_matrix
  
  # Plot a heatmap
  heatmap(as.matrix(distance_matrix),
        main = paste("Heatmap for ", metric, " distance"),
        col= heat.colors(11))

  # Obtener los valores únicos en la matriz
  legend("topright", legend = seq(min(distance_matrix), max(distance_matrix), length.out = 11),fill = heat.colors(11), title = "Values", cex = 0.8)
}
```



The results in the heatmaps indicate that the Manhattan distance is the one that seems to give better results. The intra-class distances colored in dark red are the lowest and in the heatmap they are easily distinguished. On the other hand, the inter-class distances are higher and are coloured in lighter colours.

Another conclusion that can be drawn is that the distance metric that gives the worst results is the 'maximum distance' that does not distinguish well the intra-class and the inter-class and only gives small distances to the pictures that are the same.

### REST OF THE PARAMETERS (try all 3 metrics)

Ahora ya empezamos a predecir entonces hay que dividir en train y test y transformar los datos.


Pero antes, pasamos todos los datos de 'test2' a target '0'



```{r}
# Divide the set of images into a test set and train set
prueba2 = split_train_test(files_list)

# Take the train set and the test set in sepparate dataframes 
df_train_data <- subset(prueba2,split == 'train')
df_test_data <- subset(prueba2,split != 'train')


df_test_data <- df_test_data %>%
  mutate(target = ifelse(split == 'test2', '0', target))


#1. Read the files from the dataframe
images_train = read_images(df_train_data$file)
images_test = read_images(df_test_data$file)
  
#1. Transform the data
  
train_matrix = transform_data(images_train)
test_matrix = transform_data(images_test)


```



```{r}
# Inicializar un dataframe para almacenar los resultados
resultados_df_euclidean <- data.frame(metric = character(),
                            threshold = numeric(),
                            percentage_var = numeric(),
                            k_value = numeric(),
                            accuracy_total = numeric(),
                            accuracy_belong = numeric(),
                            stringsAsFactors = FALSE)


results= list()
# Compute the distances between instances
distance_matrix= distance_matrices[['euclidean']]

thresholds = seq(min(distance_matrix), max(distance_matrix), length.out = 11)

percentage_var= list(0.85,0.90,0.95)

k_values = list(1,3,5) #we choose odd numbers to avoid ties

for (th in thresholds) {
  results[[as.character(th)]] <- list()
  
  for (var in percentage_var) {
    results[[as.character(th)]][[as.character(var)]] <- list()

    for (k_v in k_values) {
      resultado <- classifier(train_matrix, test_matrix, 1, k = k_v, thres = th, metric = 'euclidean', var, df_test_data$target)
      results[[as.character(th)]][[as.character(var)]][[as.character(k_v)]] <- resultado

      #a <- sum(as.character(resultado) == as.character(df_test_data$target)) / length(resultado)
      acc <- accuracy(resultado, df_test_data$target, df_test_data$split)

      cat('Accuracy belong= ', acc$accuracy_belong, '\n')
      cat('Accuracy total= ', acc$accuracy_target, '\n')

      # Almacenar los resultados en el dataframe
      resultados_df_euclidean <- rbind(resultados_df_euclidean, data.frame(metric = "euclidean", threshold = th, percentage_var = var, k_value = k_v, accuracy_total = acc$accuracy_target, accuracy_belong= acc$accuracy_belong ))
    }
  }
}
```






```{r}
resultado <- classifier(train_matrix, test_matrix, 0, k = 1, thres = 18.36, metric = 'euclidean', 0.95, df_test_data$target)
acc <- accuracy(resultado, df_test_data$target, df_test_data$split)
cat('Accuracy belong= ', acc$accuracy_belong, '\n')
cat('Accuracy total= ', acc$accuracy_target, '\n')

```


```{r}
# Inicializar un dataframe para almacenar los resultados
resultados_df_manhattan <- data.frame(metric = character(),
                            threshold = numeric(),
                            percentage_var = numeric(),
                            k_value = numeric(),
                            accuracy = numeric(),
                            stringsAsFactors = FALSE)


# Compute the distances between instances
distance_matrix= distance_matrices[['manhattan']]

thresholds = seq(min(distance_matrix), max(distance_matrix), length.out = 11)

percentage_var= list(0.85,0.90,0.95)

k_values = list(1,3,5) #we choose odd numbers to avoid ties

for (th in thresholds) {
  for (var in percentage_var) {
    for (k_v in k_values) {
      resultado <- classifier(train_matrix, test_matrix, 1, k = k_v, thres = th, metric = 'manhattan', var, df_test_data$target)
      a <- sum(resultado == as.character(df_test_data$target)) / length(resultado)
      cat('Accuracy= ', a, '\n')
      # Almacenar los resultados en el dataframe
      resultados_df_manhattan <- rbind(resultados_df_manhattan, data.frame(metric = "manhattan", threshold = th, percentage_var = var, k_value = k_v, accuracy = a))
    }
  }
}
```


